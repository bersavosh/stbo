{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03a4c1e-6229-4b50-93e3-ca7cb17f7faf",
   "metadata": {},
   "source": [
    "# Stats workshop\n",
    "\n",
    "All the parts that require action (either in the code or equations) are flagged by `<your turn>` or $\\color{red}{<your~turn>}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321a791-1929-491b-9244-046d0b1b8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.color_palette(\"hls\", 8)\n",
    "\n",
    "# Setting matplotlib fonts\n",
    "from matplotlib import rc\n",
    "font = {'family': 'serif',\n",
    "        'weight': 'bold',\n",
    "        'size': '14'}\n",
    "rc('font', **font)\n",
    "\n",
    "\n",
    "# Below is a set of colors for matplotlib that is colorblind-friendly\n",
    "# To use them in plotting commands, you can simply set \"color=colorset[N]\",\n",
    "# where N is an integer in [0,16), reflecting the index of the colors below.\n",
    "colorset = ['#000000','#00270C','#00443C','#005083',\n",
    "            '#034BCA','#483CFC','#9C2BFF','#EB24F4',\n",
    "            '#FF2DC2','#FF4986','#FF7356','#FFA443',\n",
    "            '#EBD155','#D3F187','#D7FFC8','#FFFFFF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dffd07-1c49-45f9-9a80-3783a04c6aa8",
   "metadata": {},
   "source": [
    "## Motivation: Algebra of random variables and probabilistic computation\n",
    "\n",
    "When dealing with algebra of random variables, we are no longer *just* interested in a single value, but also what their distribution dictates on the results. For example:\n",
    "\n",
    "If X and Y are two random variables with distributions $p_X(X)$ and $p_Y(Y)$, we might be interested in $Z = X+Y$ which itself is a random variable. \n",
    "\n",
    "For example, if \n",
    "\n",
    "$$ X\\sim \\textrm{Normal}(\\mu_X,\\sigma_X) $$\n",
    "$$ Y\\sim \\textrm{Normal}(\\mu_Y,\\sigma_Y) $$\n",
    "\n",
    "and if $X$ and $Y$ are independent, then, one can show that\n",
    "\n",
    "$$ Z \\sim \\textrm{Normal}(\\mu_X+\\mu_Y,\\sqrt{\\sigma_X^2 + \\sigma_Y^2})$$\n",
    "\n",
    "You might recall this is similar to error propagation (in fact it is the underlying algebra of it). While analytical proofs are the ultimate goal and the ideal solution, they are not always practical, so an alternative approach is to approximate a distribution through sampling.\n",
    "\n",
    "### Monte Carlo simulation for random variable algebra\n",
    "Assume $X\\sim \\textrm{Normal}(\\mu_X=5,\\sigma_X=3) $ and $Y\\sim \\textrm{Normal}(\\mu_Y=15,\\sigma_Y=5)$. We define $Z=X+Y$. \n",
    "\n",
    "#### Exercise - part a: Using tools available in `scipy.stats` (e.g., see [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm)), perform Monte Carlo sampling from the distribution of $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67522f73-c821-49f3-9883-ec444d1b7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "MC_sample_size = 5000\n",
    "\n",
    "X_sample = \n",
    "Y_sample = \n",
    "Z_sample = \n",
    "\n",
    "print('Type of Z_sample:\\n', type(Z_sample))\n",
    "print('Shape of Z_sample:\\n', Z_sample.shape)\n",
    "print('A glimpse of Z_sample:\\n',Z_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd6dbc-431c-4fd6-8831-2cdf6d4fc504",
   "metadata": {},
   "source": [
    "#### Exercise - part b: Make a histogram of the resulting MC sample of $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a8e7a-f012-4f3a-8938-7d264c524572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# Output should be a single plot\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# <your turn>\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('Z')\n",
    "ax.set_ylabel('p(Z)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb9d393-31bb-49ed-b1bc-70034a325fe9",
   "metadata": {},
   "source": [
    "#### Exercise - part c: Generate a curve representing $p(Z)$ based on the analytical form discussed in the earlier dicussion. Plot this analytical form on top of the histogram from part b and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d858db-35d9-4b6a-80f2-1a829c0e2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# Output should be a single plot\n",
    "\n",
    "theoretical_Z = \n",
    "theoretical_pZ = \n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# <your turn>\n",
    "\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('Z')\n",
    "ax.set_ylabel('p(Z)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b97c2-630f-4987-a6f0-a94e33b82190",
   "metadata": {},
   "source": [
    "Broadly speaking, in this workshop we are interested in a more generalized numerical method to calculate distribution of variables like $Z$ as a gateway to our probabilistic inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c91a6d-cf84-48c8-ba6b-4dcfb83f4091",
   "metadata": {},
   "source": [
    "## Probabilistic computations and probabilistic languages\n",
    "\n",
    "Naively, a probabilistic computer language is a language that allows definition of random variables and performing of algebraic operations on such variables, to enable probabilistic computation. What we did using `scipy.stats` was a simple version of what a probabilistic language can help us with. However, our apprach with `scipy.stats` starts to unravel if we are dealing with ill-normalized distributions (remember the problem with model evidence and normalization of posterior probability density?).\n",
    "\n",
    "So, let's perform a similar task as we did above, but in a probabilistic language. We will use a probabilistic language built in Python called [PyMC](https://www.pymc.io/welcome.html).\n",
    "\n",
    "### First steps in PYMC\n",
    "We define the following random variables:\n",
    "\n",
    "$$ X \\sim \\rm{Normal}(\\mu=5,\\sigma=2) $$\n",
    "$$ Y \\sim \\rm{Laplace(\\mu=2,b=1)}$$\n",
    "\n",
    "We define $Z= XY$, and we are interested in its probability distribution.\n",
    "\n",
    "#### Exercise - part a: Have a look at how PYMC [defines random variable](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html#model-specification) and how it parameterizes a [Laplace distribution](https://www.pymc.io/projects/docs/en/latest/api/distributions/generated/pymc.Laplace.html) and define random variables $X,Y,Z$ based on the distributions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3c056-d466-4f65-a4d8-2cba7d8d2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# This cell has no output\n",
    "\n",
    "with pm.Model() as my_first_model:\n",
    "    X = \n",
    "    Y = \n",
    "    Z = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac1816-df88-4405-9397-d0713306c32d",
   "metadata": {},
   "source": [
    "#### Exercise - part b: Print and explore the computational \"type\" of your defined variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a8512-4cea-47ea-91f9-0edd9fbe4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d68022-20eb-4d93-b396-9b9ac68db2e5",
   "metadata": {},
   "source": [
    "#### Exercise - part c: Perform MC sampling for all three variables. Have a look at `pm.sample` [documentation](https://www.pymc.io/projects/docs/en/stable/api/generated/pymc.sample.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b77f15-a440-4507-bf9b-49eba127e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# This cell will print outputs automatically about sampling progression\n",
    "\n",
    "with my_first_model:\n",
    "    mc_sample = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89bf1f9-c696-4649-80e2-0a62d08c6263",
   "metadata": {},
   "source": [
    "We will explore the computational details of the output above shortly, but for now, let's treat it a little superficially:\n",
    "\n",
    "#### Exercise - part d: Explore the output of sampling. Hint: have a look at documentation of [inference data](https://python.arviz.org/en/latest/getting_started/WorkingWithInferenceData.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed758f-6cff-47fb-8ca7-93c678ff589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ba203-a733-438e-a54e-53fa1fa5456d",
   "metadata": {},
   "source": [
    "### Inspecting MC (and MCMC) outputs efficiently\n",
    "\n",
    "PYMC ecosystem provides a lot of effective tools to explore our inference and outputs. Here we will use [Arviz](https://python.arviz.org/en/latest/index.html) to visuaize our reuslts.\n",
    "\n",
    "#### Exercise - part a: Have a look at the documentation of [`plot_density`](https://python.arviz.org/en/latest/api/generated/arviz.plot_density.html#arviz.plot_density) (an example [here](https://python.arviz.org/en/latest/examples/plot_density_single.html)) in Arviz and plot the results of our sampling using that. Explore how $Z$ looks based on the original premise of our \"model\" ($Z=XY$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6cb334-79ff-4ef3-b563-307d03c6d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf5a8a-bd20-4c98-83c0-1d59d90999a3",
   "metadata": {},
   "source": [
    "#### Exercise - part b: Have a look at the documentation of [`plot_pair`](https://python.arviz.org/en/latest/api/generated/arviz.plot_pair.html#arviz.plot_pair) (an example [here](https://python.arviz.org/en/latest/examples/plot_pair_point_estimate.html)) in Arviz and plot the results of our sampling using that. Explore what the plot represents regarding joint and marginal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed00c1e7-79a9-42e3-9fbc-7f0b14178086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7b389-4189-4421-83c4-d259bc3588fe",
   "metadata": {},
   "source": [
    "### Another quick but perhaps counter-intuituve example\n",
    "\n",
    "We define:\n",
    "\n",
    "$$ X\\sim\\textrm{Uniform}(\\min=0,\\max=5)$$\n",
    "$$ Z = X^2 $$\n",
    "\n",
    "#### Exercise: First think about what would $p(Z)$ look like, then sample and visualize to check if you were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a0eb5-4fd5-4528-bfea-375e77cd9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# Make a model, sample, then plot.\n",
    "\n",
    "with pm.Model() as my_second_model:\n",
    "    X = \n",
    "    Z = \n",
    "    mc_sample = \n",
    "\n",
    "## Plotting doesn't need to be in the model \"context\", put it below here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8f95c-233d-433d-9a38-1c1fbf9577cc",
   "metadata": {},
   "source": [
    "### Hierarchical random variables\n",
    "\n",
    "In the cases above, we mostly performed simple arithmetic. But random variable algebra can get a bit more complex. For example, imagine we define the following quantities and  **hierarchy**:\n",
    "\n",
    "$$ \\nu_{\\rm{H}} \\sim \\textrm{Lorentz}(\\mu_L=10, \\sigma_L=1) $$\n",
    "\n",
    "$$ T \\sim \\textrm{laplace}(\\mu_T = 100, b_T = 10)$$\n",
    "\n",
    "$$ \\nu_{\\rm{obs}} \\sim \\textrm{Normal}(\\mu_{\\rm{obs}}=\\nu_{\\rm{H}}, \\sigma_{\\rm{obs}}=\\sqrt{T}) $$\n",
    "\n",
    "*This is a naive model for the impact of [lifetime broadening](https://en.wikipedia.org/wiki/Spectral_line#Natural_broadening) and [thermal broadening](https://en.wikipedia.org/wiki/Doppler_broadening) on width of spectral lines.*\n",
    "\n",
    "#### Exercise: Use PyMC to model how these physical effects (random variables) influence each other and plot their density using `plot_density`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d9328-4c93-4513-9388-0f46cd0d3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# Make a model, sample, then plot.\n",
    "\n",
    "with pm.Model() as my_line_model:\n",
    "    nu_H = \n",
    "    T = \n",
    "    nu_T = \n",
    "    mc_sample = \n",
    "\n",
    "## Plotting doesn't need to be in the model \"context\", put it below here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097bdba-a9cc-49f8-b789-353a24e7e95c",
   "metadata": {},
   "source": [
    "Now let us apply our tools on probabilistic computation to our problems in inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08ee47-0889-4a46-9690-95e822b3ecd8",
   "metadata": {},
   "source": [
    "## linear regression\n",
    "\n",
    "Starting with the example in the lecture, we have made $N$ independent measurements of a quantity $Y$ (with each measurement containing normally-distributed uncertainties), at different values of quantity $X$. Assuming $Y$ as a function of $X$, we want to infer a model for the \"model\" $Y$ (which we label $Y_{\\rm{Model}}$), given what we can *observe* as $Y$ ($Y_{\\rm{obs}}$).\n",
    "\n",
    "### Data\n",
    "\n",
    "Our data consists of three numbers per measurement:\n",
    "\n",
    "$$ x = [x_1,\\cdots,x_N] $$\n",
    "$$ \\hat{y}_{\\rm{obs}} = [\\hat{y}_1,\\cdots,\\hat{y}_N] $$\n",
    "$$ \\hat{\\sigma} = [\\hat{\\sigma}_1,\\cdots,\\hat{\\sigma}_N] $$\n",
    "\n",
    "\n",
    "In this unit we will use [Pandas](https://pandas.pydata.org/) for data operations. Here is [a quick cheat sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4414bd4-0c6d-44f3-bc98-31a65c9e5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pd.read_csv('https://www.dropbox.com/scl/fi/a8s0za7o1k16b6yee2rol/data.csv?rlkey=pzkzvfy29081omdavzu4kkz7v&dl=1')\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805e4de-dcd0-4acd-81af-50a95af78b67",
   "metadata": {},
   "source": [
    "### EDA\n",
    "#### Exercise: Make a scatter plot the measurements and uncertainties of $\\hat{y}_{\\rm{obs}}$ as a function of $x$. To do this, you can simply use `plt.errorbar()` in matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f8120-ade2-403e-8f40-fb25a786f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# <your turn>\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3888fe3-d3f1-4c9b-b017-203b26eb8885",
   "metadata": {},
   "source": [
    "### Our model\n",
    "\n",
    "Similar to the lecture, we assume that our understanding of the physics, hypothetically, suggest that \n",
    "$$ Y_{\\rm{Model}}(x; m, d) = m x + d $$\n",
    "\n",
    "and similar to the lecture we assume the following priors on $m$ and $d$:\n",
    "\n",
    "$$ m \\sim \\textrm{Uniform}(\\min=0,\\max=10) $$\n",
    "$$ d \\sim \\textrm{Uniform}(\\min=-20,\\max=20) $$\n",
    "\n",
    "and we define that\n",
    "\n",
    "$$ \\hat{Y}_{\\rm{obs}} \\sim \\textrm{Normal}(Y_{\\rm{Model}}(x),\\sigma_Y) $$\n",
    "\n",
    "and we remember that we consider $\\hat{y}_{\\rm{obs}} = [\\hat{y}_1,\\cdots,\\hat{y}_N]$ as random draws of $\\hat{Y}_{\\rm{obs}}$.\n",
    "\n",
    "\n",
    "\n",
    "#### Exercise - part a: Build a PyMC model with the variables above. With the following steps:\n",
    " - Start with the data. Data can be defined in a PyMC model using `pm.Data`.\n",
    " - Then add the model parameters and variables we have defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f882e22-f06e-4529-bc7c-7d08b68cb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# just define the model and its components, no sampling or plotting needed here.\n",
    "\n",
    "with pm.Model() as regression_model:\n",
    "    ## First define your data here:\n",
    "\n",
    "    ## Now define your model variables\n",
    "\n",
    "\n",
    "\n",
    "# No plotting or sampling needed yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1020d02-4320-4ba1-a279-3d319b640265",
   "metadata": {},
   "source": [
    "#### Exercise - part b: Explore the model structures by making a diagram of model's [plate notation](https://en.wikipedia.org/wiki/Plate_notation). For this purpose, you can use `pm.model_to_graphviz` (see documentation [here](https://www.pymc.io/projects/docs/en/v5.6.1/api/generated/pymc.model_to_graphviz.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e446960-cac2-4964-9bce-c2836eafd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb19ff-8ced-482b-824b-b76438133dbc",
   "metadata": {},
   "source": [
    "#### Exercise - part c: Our model has a problem, can you spot it? fix the issue in the cell below and replot the plate notation. \n",
    "(*hint: where is the link between our data and $\\hat{Y}_{\\rm{obs}}$ variable?*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e45123-9608-4068-91fb-c779625b2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "# redefine the model and replot the model graph\n",
    "\n",
    "with pm.Model() as regression_model:\n",
    "    ## First define your data here:\n",
    "\n",
    "    ## Now define your model variables\n",
    "\n",
    "\n",
    "\n",
    "# graph visualization can be put under here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7570e8-9b4c-439e-a4be-58cd485b7517",
   "metadata": {},
   "source": [
    "### MCMC sampling\n",
    "\n",
    "Note that we are now actually performing MCMC (and not MC).\n",
    "\n",
    "#### Exercise - part a: perform sampling with the model we defined above. Run your sampling with `discard_tuned_samples=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea2c62-6cb2-43fc-aeb7-78f1b466de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n",
    "with regression_model:\n",
    "    regression_mcmc_sample = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd522ae3-7dfc-46ec-8b8d-ab1f1184d93a",
   "metadata": {},
   "source": [
    "#### Exercise - part b: Assess sampling performance. Think about what the sampling progress bar and table show. Print the resulting inference data `regression_mcmc_sample` to explore what is captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361634f-c6e7-406f-9e22-27aa41476723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2603ea7-d951-410d-b7ae-e4bff970b5e1",
   "metadata": {},
   "source": [
    "#### Exercise - part c: Use `az.plot_trace` to look at how your chains have \"walked\" (use `var_names=['m','d']` to focus on just these parameters). First do this for `posterior` (the default), then do the same for `warmup_posterior`. Do you notice anything unusual?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc8085-437e-46fa-b4e0-acfc6efed8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "## output should be two separate figures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13c6f3-fd67-4043-b15d-cc986db9684f",
   "metadata": {},
   "source": [
    "### Model fitting results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ff268-ec93-498c-8cce-73aceb056970",
   "metadata": {},
   "source": [
    "#### Exercise - part a: Print summary of the posterior with `pm.summary`. Think about what the values in the summary table mean. Use 68% HDI probability for interval estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b653387-0d36-45bf-ba06-64ba0e3e8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n",
    "fit_summary = \n",
    "\n",
    "fit_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba312f20-641a-48c5-8076-56f0848d9de4",
   "metadata": {},
   "source": [
    "#### Exercise - part b: using plotting functions we have discussed in earlier exercises, plot the marginal posterior samples (\"densities\") of $m$ and $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f69dd8-0abf-43b7-89cd-9cac45f0de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650468f4-6ef4-434f-8721-8ac915eba1b4",
   "metadata": {},
   "source": [
    "#### Exercise - part c: using plotting functions we have discussed in earlier exercises, plot the joint and margian posterior samples of $m$ and $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abca6e3-f176-431a-acc5-80061cf15272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31066c5-c154-4df6-af1d-efd9a7298e1d",
   "metadata": {},
   "source": [
    "#### Exercise - part d: Reuse your code from plotting the data, and add a line representing the model with posterior means.\n",
    "*hint: you can extract the exact values from your inference data `regression_mcmc_sample.posterior['m'].mean().values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea6cb1-2b4b-42d2-89b8-e185edc0cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "mean_m = \n",
    "mean_d = \n",
    "test_x = \n",
    "test_y = \n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# <your turn>\n",
    "\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc7dfe-524d-4479-8243-be04cc2be1c5",
   "metadata": {},
   "source": [
    "#### Exercise - part e: Reuse your code from plotting above and visualize 99% HDI of $Y_{\\rm{model}}$. You can do this using `az.plot_hdi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a0c44-a6a3-49bc-af2a-309a08b329e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your turn>\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# <your turn>\n",
    "\n",
    "\n",
    "\n",
    "# Plot cosmetics\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db12c5-efae-46df-adf5-2ae4b3a7c3c1",
   "metadata": {},
   "source": [
    "## You can now save the notebook and download it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc5",
   "language": "python",
   "name": "pymc5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
